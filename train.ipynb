{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c57dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fb56a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import time\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0794b2",
   "metadata": {},
   "source": [
    "## 1. Collect Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40b589f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['awake', 'drowsy']\n",
    "\n",
    "IMAGES_PATH_TRAIN = os.path.join('data', 'train', 'images')\n",
    "IMAGES_PATH_TEST = os.path.join('data', 'test', 'images')\n",
    "\n",
    "\n",
    "number_imgs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4985e5d",
   "metadata": {},
   "source": [
    "### 1.1. Collect Training Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4cfc10cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting Images for awake\n",
      "Collecting Images for awake, and image number 0\n",
      "Collecting Images for awake, and image number 1\n",
      "Collecting Images for drowsy\n",
      "Collecting Images for drowsy, and image number 0\n",
      "Collecting Images for drowsy, and image number 1\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "for label in labels:\n",
    "    print('Collecting Images for {}'.format(label))\n",
    "    time.sleep(5)\n",
    "    \n",
    "    for image in range(number_imgs):\n",
    "        print('Collecting Images for {}, and image number {}'.format(label, image))\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        imgname = os.path.join(IMAGES_PATH_TRAIN, label+'.'+str(uuid.uuid1())+'.jpg')\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        cv2.imshow(\"Image Collection\", frame)   \n",
    "        \n",
    "        time.sleep(2)\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7961ea0b",
   "metadata": {},
   "source": [
    "### 1.2. Collect Testing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5cf45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "for label in labels:\n",
    "    print('Collecting Images for {}'.format(label))\n",
    "    time.sleep(5)\n",
    "    \n",
    "    for image in range(number_imgs):\n",
    "        print('Collecting Images for {}, and image number {}'.format(label, image))\n",
    "        \n",
    "        ret, frame = cap.read()\n",
    "        imgname = os.path.join(IMAGES_PATH_TEST, label+'.'+str(uuid.uuid1())+'.jpg')\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        cv2.imshow(\"Image Collection\", frame)   \n",
    "        \n",
    "        time.sleep(2)\n",
    "        cv2.imwrite(imgname, frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093f4248",
   "metadata": {},
   "source": [
    "## 2. Labeling images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a190117",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install labelme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d8fd9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelme"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9422c19e",
   "metadata": {},
   "source": [
    "## 3. Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d28ecfc1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'albumentations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01malbumentations\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01malb\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'albumentations'"
     ]
    }
   ],
   "source": [
    "import albumentations as alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21074cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize image augmentator\n",
    "transform = alb.Compose([alb.RandomCrop(width = 450, height = 450),\n",
    "                         alb.HorizontalFlip(p=0.5),\n",
    "                         alb.RandomBrightnessContrast(p=0.2),\n",
    "                         alb.RandomGamma(p=0.2),\n",
    "                         alb.RGBShift(p=0.2),\n",
    "                         alb.VerticalFlip(p=0.5)],\n",
    "                        bbox_params=alb.BboxParams(format='albumentations',\n",
    "                                                   label_fields = ['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab52fb4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition in ['train', 'test']:\n",
    "    for image in os.listdir(os.path.join('data', partition, 'images')):\n",
    "        \n",
    "        #Load full image name \n",
    "        img = cv2.imread(os.path.join('data', partition, 'images', image))\n",
    "        #Get the image name without the .jpg\n",
    "        img_name = image.split('.')[0] + '.' + image.split('.')[1]\n",
    "        #Format label path with the respect image name\n",
    "        label_path = os.path.join('data', partition, 'labels', f'{img_name}.json')\n",
    "        \n",
    "    #Load label\n",
    "    with open(label_path, \"r\") as f:\n",
    "        label = json.load(f)\n",
    "        \n",
    "    #Get bounding box's coordinates\n",
    "    coords = np.array(label['shapes'][0]['points']).flatten()\n",
    "    #Normalize the coordinates\n",
    "    coords = list(np.divide(coords, [640, 480, 640, 480]))\n",
    "    \n",
    "    #Get the label\n",
    "    label = label['shapes'][0]['label']\n",
    "    \n",
    "    #Generate 60 images from one base image using augmentation\n",
    "    for x in range(60):\n",
    "        transformed = transform(image = img, bboxes = [coords], class_labels=[label])\n",
    "        if transformed['bboxes'] == []:\n",
    "            break\n",
    "        \n",
    "        #Write transformed image\n",
    "        cv2.imwrite(os.path.join('data', 'augmented', partition, 'images', f'{img_name}.{x}.jpg'), transformed['images'])\n",
    "        \n",
    "        #Create a dictionanry that contain label, bounding box's coordinates and name of the image\n",
    "        annotation = {}\n",
    "        #Name of the image\n",
    "        annotation['image'] = image\n",
    "        #Bounding box's coordinates\n",
    "        annotation['bbox'] = transformed['bboxes'][0]\n",
    "        \n",
    "        #Onehot coding the label\n",
    "        if label == 'awake':\n",
    "            annotation['class'] = 0\n",
    "        else:\n",
    "            annotation['class'] = 1\n",
    "        \n",
    "        #Write the dict into a json file\n",
    "        with open(os.path.join('data', 'augmented', partition, 'labels', f'{img_name}.{x}.json'), 'w') as f:\n",
    "            json.dump(annotation, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1594997b",
   "metadata": {},
   "source": [
    "## 4. Create Data Pipeline for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90017682",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define two functions to load images and labels\n",
    "def load_image(x):\n",
    "    image = tf.io.read_file(x)\n",
    "    image = tf.io.decode_jpeg(image)\n",
    "    return image\n",
    "\n",
    "def load_labels(label_path):\n",
    "    with open(label_path.numpy(), \"r\", encoding='utf-8') as f:\n",
    "        label = json.load(f)\n",
    "    return [label['class'], label['bbox']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294605ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image pipeline\n",
    "train_images = tf.data.Dataset.list_files('data/augmented/train/images/*.jpg', shuffle=False)\n",
    "train_images = train_images.map(load_image)\n",
    "train_images = train_images.map(lambda x: tf.image.resize(x, (288,288)))\n",
    "\n",
    "test_images = tf.data.Dataset.list_files('data/augmented/test/images/*.jpg', shuffle=False)\n",
    "test_images = test_images.map(load_image)\n",
    "test_images = test_images.map(lambda x: tf.image.resize(x, (288,288)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75d0036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labels pipeline\n",
    "train_labels = tf.data.Dataset.list_files('data/augmented/train/labels/*.json', shuffle=False)\n",
    "train_labels = train_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))\n",
    "\n",
    "test_labels = tf.data.Dataset.list_files('data/augmented/test/labels/*.json', shuffle=False)\n",
    "test_labels = test_labels.map(lambda x: tf.py_function(load_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eeeb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zip images and labels \n",
    "train = tf.data.Dataset.zip((train_images, train_labels))\n",
    "train = train.shuffle(1000)\n",
    "train = train.batch(16)\n",
    "train = train.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test = tf.data.Dataset.zip((test_images, test_labels))\n",
    "test = test.shuffle(1000)\n",
    "test = test.batch(16)\n",
    "test = test.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fab7f7",
   "metadata": {},
   "source": [
    "## 5. Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8147b76",
   "metadata": {},
   "source": [
    "### 5.1. Build Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74d674f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, GlobalMaxPooling2D, Dropout, BatchNormalization, Activation\n",
    "from tensorflow.keras.applications import efficientnet_v2\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39efb748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    input_layer = Input(shape=(288,288,3))\n",
    "    base = efficientnet_v2.EfficientNetV2S(input_shape = (288, 288, 3), include_top = False, pooling=\"max\")(input_layer)\n",
    "\n",
    "    #Classification\n",
    "    hidden1 = Dense(2024, kernel_regularizer = regularizers.L2(0.0001), use_bias = False)(base)\n",
    "    norm1 = BatchNormalization()(hidden1)\n",
    "    act1 = Activation('relu')(norm1)\n",
    "    hidden3 = Dense(512, kernel_regularizer = regularizers.L2(0.00001), use_bias = False)(act1)\n",
    "    norm2 = BatchNormalization()(hidden3)\n",
    "    act3 = Activation('relu')(norm2)\n",
    "    hidden4 = Dense(256, kernel_regularizer = regularizers.L2(0.00001), use_bias = False)(act3)\n",
    "    norm3 = BatchNormalization()(hidden4)\n",
    "    act4 = Activation('relu')(norm3)\n",
    "    hidden6 = Dense(64, activation = 'relu')(act4)\n",
    "\n",
    "    class_output = Dense(1, activation = 'linear')(hidden6)\n",
    "\n",
    "    #Regression for bounding boxes\n",
    "    hidden12 = Dense(2048, kernel_regularizer = regularizers.L2(0.0001), use_bias = False)(base)\n",
    "    norm12 = BatchNormalization()(hidden12)\n",
    "    act12 = Activation('relu')(norm12)\n",
    "    hidden22 = Dense(1024, kernel_regularizer = regularizers.L2(0.00001), use_bias = False)(act12)\n",
    "    norm12 = BatchNormalization()(hidden22)\n",
    "    act22 = Activation('relu')(norm12)\n",
    "    hidden32 = Dense(512, kernel_regularizer = regularizers.L2(0.000001), use_bias = False)(act22)\n",
    "    norm22 = BatchNormalization()(hidden32)\n",
    "    act32 = Activation('relu')(norm22)\n",
    "    hidden42 = Dense(256, kernel_regularizer = regularizers.L2(0.000001))(act32)\n",
    "#     #norm32 = BatchNormalization()(hidden42)\n",
    "    act42 = Activation('relu')(hidden42)\n",
    "    \n",
    "    reg_output = Dense(4, activation = 'sigmoid')(act42)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs = [class_output, reg_output])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf227e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)           [(None, 288, 288, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " efficientnetv2-s (Functional)  (None, 1280)         20331360    ['input_5[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 2048)         2621440     ['efficientnetv2-s[0][0]']       \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 2024)         2590720     ['efficientnetv2-s[0][0]']       \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 2048)        8192        ['dense_6[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 2024)        8096        ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 2048)         0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 2024)         0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 1024)         2097152     ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 512)          1036288     ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 1024)        4096        ['dense_7[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 512)         2048        ['dense_2[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 1024)         0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 512)          0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " dense_8 (Dense)                (None, 512)          524288      ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 256)          131072      ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 512)         2048        ['dense_8[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 256)         1024        ['dense_3[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 512)          0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 256)          0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 256)          131328      ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 64)           16448       ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 256)          0           ['dense_9[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 1)            65          ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 4)            1028        ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 29,506,693\n",
      "Trainable params: 29,340,069\n",
      "Non-trainable params: 166,624\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_struct = build_model()\n",
    "model_struct.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a78d5d3",
   "metadata": {},
   "source": [
    "### 5.2. Define Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f01b571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss function for bounding boxes\n",
    "def box_loss(y_pred, y_true):\n",
    "    coords_delta = tf.reduce_sum(tf.square(y_pred[:,:2] - y_true[:,:2]))\n",
    "\n",
    "    h_true = y_true[:,3] - y_true[:,1]\n",
    "    w_true = y_true[:,2] - y_true[:,0]\n",
    "\n",
    "    h_pred = y_pred[:,3] - y_pred[:,1]\n",
    "    w_pred = y_pred[:,2] - y_pred[:,0]\n",
    "\n",
    "    frame_delta = tf.reduce_sum(tf.square(h_true - h_pred) + tf.square(w_true - w_pred))\n",
    "\n",
    "    return coords_delta + frame_delta\n",
    "\n",
    "class_losses = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
    "box_losses = box_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24324d91",
   "metadata": {},
   "source": [
    "### 5.3. Define Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7100594",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_per_epochs = len(train)\n",
    "lr_decay = (1./0.75-1)/batch_per_epochs\n",
    "opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.001, decay = lr_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d603b718",
   "metadata": {},
   "source": [
    "### 5.4. Build Custom Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9292c207",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrowsyDetector(Model):\n",
    "    def __init__(self, model, **kargs):\n",
    "        super().__init__(**kargs)\n",
    "        self.model = model\n",
    "\n",
    "    def compile(self, opt, classloss, regloss, **kargs):\n",
    "        super().compile(**kargs)\n",
    "        self.classloss = classloss\n",
    "        self.regloss = regloss\n",
    "        self.opt = opt\n",
    "\n",
    "    def train_step(self, batch, **kargs):\n",
    "\n",
    "        X, y = batch\n",
    "        \n",
    "        #Optimization\n",
    "        with tf.GradientTape() as tape:\n",
    "            classes, coords = self.model(X, training=True)\n",
    "\n",
    "            batch_classloss = self.classloss(y[0], classes)\n",
    "            batch_regloss = self.regloss(tf.cast(y[1], tf.float32), coords)\n",
    "\n",
    "            total_loss = batch_classloss + 0.5*batch_regloss \n",
    "\n",
    "            diff = tape.gradient(total_loss, self.model.trainable_variables)\n",
    "\n",
    "        opt.apply_gradients(zip(diff, self.model.trainable_variables))\n",
    "\n",
    "        return {'Train Total Loss':total_loss, 'Train Regression Loss':batch_regloss, 'Train Classification Loss':batch_classloss}\n",
    "\n",
    "    def test_step(self, batch, **kargs):\n",
    "        X, y = batch\n",
    "\n",
    "        classes, coords = self.model(X, training=False)\n",
    "\n",
    "        batch_classloss = self.classloss(y[0], classes)\n",
    "        batch_regloss = self.regloss(tf.cast(y[1], tf.float32), coords)\n",
    "\n",
    "        total_loss = batch_classloss + 0.5*batch_regloss\n",
    "\n",
    "        return {'Total Loss':total_loss, 'Regression Loss':batch_regloss, 'Classification Loss':batch_classloss}\n",
    "\n",
    "    def call(self, X, **kargs):\n",
    "        return self.model(X, **kargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0989e4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DrowsyDetector(model_struct)\n",
    "model.compile(opt = opt, classloss = class_losses, regloss = box_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06303b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = 'training/checkpoint/weight/cp.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69572140",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs = 40, validation_data = test, verbose = 1, callbacks = [cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a37b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test.as_numpy_iterator().next()\n",
    "test_images = test_data[0]\n",
    "test_labels = test_data[1][0]\n",
    "pred = model.predict(test_images)\n",
    "\n",
    "pred_labels = [1 if x > 0.5 else 0 for x in pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a557f1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "466aa61b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9326171875\n",
      "Recall: 0.9862204724409449\n",
      "Precision: 0.8898756660746003\n",
      "F1 Score: 0.9355742296918768\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy: ' + str(accuracy_score(test_labels, pred_labels)))\n",
    "print('Recall: '+str(recall_score(test_labels, pred_labels)))\n",
    "print('Precision: '+str(precision_score(test_labels, pred_labels)))\n",
    "print('F1 Score: '+str(f1_score(test_labels, pred_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d72e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/eff', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c28691cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf6b57da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('models/eff', compile = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1fe97fe5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"drowsy_detector\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " model (Functional)          [(None, 1),               23425249  \n",
      "                              (None, 4)]                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,425,249\n",
      "Trainable params: 23,299,569\n",
      "Non-trainable params: 125,680\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0190a016",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n",
      "1/1 [==============================] - 0s 274ms/step\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "1/1 [==============================] - 0s 221ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 250ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 204ms/step\n",
      "1/1 [==============================] - 0s 267ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 232ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 236ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1/1 [==============================] - 0s 217ms/step\n",
      "1/1 [==============================] - 0s 235ms/step\n",
      "1/1 [==============================] - 0s 219ms/step\n",
      "1/1 [==============================] - 0s 381ms/step\n",
      "1/1 [==============================] - 0s 392ms/step\n",
      "1/1 [==============================] - 0s 361ms/step\n",
      "1/1 [==============================] - 0s 440ms/step\n",
      "1/1 [==============================] - 1s 506ms/step\n",
      "1/1 [==============================] - 0s 447ms/step\n",
      "1/1 [==============================] - 0s 470ms/step\n",
      "1/1 [==============================] - 0s 377ms/step\n",
      "1/1 [==============================] - 0s 424ms/step\n",
      "1/1 [==============================] - 1s 953ms/step\n",
      "1/1 [==============================] - 0s 401ms/step\n",
      "1/1 [==============================] - 0s 366ms/step\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while(True):\n",
    "    _, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame = frame[50:500, 50:500,:]\n",
    "    \n",
    "    #Pre-proccessing\n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    resized = tf.image.resize(rgb, (288,288))\n",
    "    \n",
    "    \n",
    "    #Make real time prediction\n",
    "    pred = model.predict(np.expand_dims(resized, axis = 0))\n",
    "    \n",
    "    if pred[0] < 0.5:\n",
    "        label = 'awake'\n",
    "    else:\n",
    "        label = 'drowsy'\n",
    "    coords = pred[1][0]\n",
    "    \n",
    "    #Show the bounding box\n",
    "\n",
    "    \n",
    "    #Show the label\n",
    "    if label == 'awake':\n",
    "        cv2.rectangle(frame, \n",
    "                        tuple(np.multiply(coords[:2], [450, 450]).astype(int)),\n",
    "                        tuple(np.multiply(coords[2:], [450, 450]).astype(int)), \n",
    "                        (255,0,0), 2)\n",
    "            \n",
    "        cv2.rectangle(frame, \n",
    "                          tuple(np.add(np.multiply(coords[:2], [450,450]).astype(int), \n",
    "                                        [0,-30])),\n",
    "                          tuple(np.add(np.multiply(coords[:2], [450,450]).astype(int),\n",
    "                                        [100,0])), \n",
    "                                (255,0,0), -1)\n",
    "        \n",
    "        cv2.putText(frame, label, tuple(np.add(np.multiply(coords[:2], [450,450]).astype(int),\n",
    "                                                       [0,-5])),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "    else: \n",
    "        cv2.rectangle(frame, \n",
    "                        tuple(np.multiply(coords[:2], [450, 450]).astype(int)),\n",
    "                        tuple(np.multiply(coords[2:], [450, 450]).astype(int)), \n",
    "                        (0,0,255), 2)\n",
    "            \n",
    "        cv2.rectangle(frame, \n",
    "                          tuple(np.add(np.multiply(coords[:2], [450,450]).astype(int), \n",
    "                                        [0,-30])),\n",
    "                          tuple(np.add(np.multiply(coords[:2], [450,450]).astype(int),\n",
    "                                        [110,0])), \n",
    "                                (0,0,255), -1)\n",
    "        \n",
    "        cv2.putText(frame, label, tuple(np.add(np.multiply(coords[:2], [450,450]).astype(int),\n",
    "                                                       [0,-5])),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('c', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfba2f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
